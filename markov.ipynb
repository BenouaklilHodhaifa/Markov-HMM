{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Benouaklil\n",
      "[nltk_data]     Hodhaifa\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading every Sherlock Holmes adventure!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of lines =  215021\n"
     ]
    }
   ],
   "source": [
    "story_path = \"./sherlock/\"\n",
    "\n",
    "def read_all_stories(story_path):\n",
    "    txt = []\n",
    "    for _, _, files in os.walk(story_path):\n",
    "        for file in files:\n",
    "            with open(story_path+file) as f:\n",
    "                for line in f:\n",
    "                    line = line.strip()\n",
    "                    if line=='----------': break\n",
    "                    if line!='':txt.append(line)\n",
    "    return txt\n",
    "        \n",
    "stories = read_all_stories(story_path)\n",
    "print(\"number of lines = \", len(stories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of words =  2332247\n"
     ]
    }
   ],
   "source": [
    "def clean_txt(txt):\n",
    "    cleaned_txt = []\n",
    "    for line in txt:\n",
    "        line = line.lower()\n",
    "        line = re.sub(r\"[,.\\\"\\'!@#$%^&*(){}?/;`~:<>+=-\\\\]\", \"\", line)\n",
    "        tokens = word_tokenize(line)\n",
    "        words = [word for word in tokens if word.isalpha()]\n",
    "        cleaned_txt+=words\n",
    "    return cleaned_txt\n",
    "\n",
    "cleaned_stories = clean_txt(stories)\n",
    "print(\"number of words = \", len(cleaned_stories))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Markov Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_markov_model(cleaned_stories, n_gram=2):\n",
    "    markov_model = {}\n",
    "    for i in range(len(cleaned_stories)-n_gram-1):\n",
    "        curr_state, next_state = \"\", \"\"\n",
    "        for j in range(n_gram):\n",
    "            curr_state += cleaned_stories[i+j] + \" \"\n",
    "            next_state += cleaned_stories[i+j+n_gram] + \" \"\n",
    "        curr_state = curr_state[:-1]\n",
    "        next_state = next_state[:-1]\n",
    "        if curr_state not in markov_model:\n",
    "            markov_model[curr_state] = {}\n",
    "            markov_model[curr_state][next_state] = 1\n",
    "        else:\n",
    "            if next_state in markov_model[curr_state]:\n",
    "                markov_model[curr_state][next_state] += 1\n",
    "            else:\n",
    "                markov_model[curr_state][next_state] = 1\n",
    "    \n",
    "    # calculating transition probabilities\n",
    "    for curr_state, transition in markov_model.items():\n",
    "        total = sum(transition.values())\n",
    "        for state, count in transition.items():\n",
    "            markov_model[curr_state][state] = count/total\n",
    "        \n",
    "    return markov_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "markov_model = make_markov_model(cleaned_stories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of states =  208716\n"
     ]
    }
   ],
   "source": [
    "print(\"number of states = \", len(markov_model.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All possible transitions from 'the game' state: \n",
      "\n",
      "{'your letter': 0.02702702702702703, 'was up': 0.09009009009009009, 'is afoot': 0.036036036036036036, 'for the': 0.036036036036036036, 'was in': 0.02702702702702703, 'is hardly': 0.02702702702702703, 'would have': 0.036036036036036036, 'is up': 0.06306306306306306, 'is and': 0.036036036036036036, 'in their': 0.036036036036036036, 'was whist': 0.036036036036036036, 'in that': 0.036036036036036036, 'the lack': 0.036036036036036036, 'for all': 0.06306306306306306, 'may wander': 0.02702702702702703, 'now a': 0.02702702702702703, 'my own': 0.02702702702702703, 'at any': 0.02702702702702703, 'mr holmes': 0.02702702702702703, 'ay whats': 0.02702702702702703, 'my friend': 0.02702702702702703, 'fairly by': 0.02702702702702703, 'is not': 0.02702702702702703, 'was not': 0.02702702702702703, 'was afoot': 0.036036036036036036, 'worth it': 0.02702702702702703, 'you are': 0.02702702702702703, 'i am': 0.02702702702702703, 'now count': 0.02702702702702703}\n"
     ]
    }
   ],
   "source": [
    "print(\"All possible transitions from 'the game' state: \\n\")\n",
    "print(markov_model['the game'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating Sherlock Holmes stories!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_story(markov_model, limit=100, start='my god'):\n",
    "    n = 0\n",
    "    curr_state = start\n",
    "    next_state = None\n",
    "    story = \"\"\n",
    "    story+=curr_state+\" \"\n",
    "    while n<limit:\n",
    "        next_state = random.choices(list(markov_model[curr_state].keys()),\n",
    "                                    list(markov_model[curr_state].values()))\n",
    "        \n",
    "        curr_state = next_state[0]\n",
    "        story+=curr_state+\" \"\n",
    "        n+=1\n",
    "    return story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.  dear holmes my previous letters and is now evident were to prevent anything like public exposure of private \n",
      "1.  dear holmes said i thought that nothing could be seen except my own and it is quite certain \n",
      "2.  dear holmes i ejaculated my dear dear son now that he knew that i took some time before \n",
      "3.  dear holmes if i call upon you and i and i have already said that i was very \n",
      "4.  dear holmes oh yes i know where all gossip is welcome this weakness of his nature it was \n",
      "5.  dear holmes and tell her these things and followed him closely and to keep herself in your room \n",
      "6.  dear holmes i exclaimed in unfeigned admiration it is so common in an english coat frayed at the \n",
      "7.  dear holmes said i precisely he opened the door to say that i make my bow and return \n",
      "8.  dear holmes i exclaimed perhaps one of those marks on her arm that you make such reparation as \n",
      "9.  dear holmes if i can i be of value you can see the two charts all ready signed \n",
      "10.  dear holmes i thought of all our difficulties vanish as easily said sherlock holmes we will have no \n",
      "11.  dear holmes what do you make of it but the more he drank the less i gasped with \n",
      "12.  dear holmes oh yes i have already explained the relationship comes over from greece to interfere with him \n",
      "13.  dear holmes i exclaimed how on earth you got yourself mixed up in an apron she explained that \n",
      "14.  dear holmes i have no doubt that my friend would stay some little time said holmes all great \n",
      "15.  dear holmes what do you mean for answer he took a fancy to me that you were there \n",
      "16.  dear holmes it is clear that like myself and he has spent most of the facts which you \n",
      "17.  dear holmes that i was amused by her servants as being insane an examination showed that the door \n",
      "18.  dear holmes am i justified in laying them by the charming society whose leader lies in the one \n",
      "19.  dear holmes am i allowed to die out with due discretion the incident itself may however have been \n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_story(markov_model, start=\"dear holmes\", limit=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.  my dear holmes i went to bed and the note with which the crime was committed so as \n",
      "1.  my dear watson i think you can find nothing against him either here in my pocket there i \n",
      "2.  my dear watson i am very much so and the adventure of the musgrave ritual arthur conan doyle \n",
      "3.  my dear watson i think we are a good fellow said holmes it is very essential to me \n",
      "4.  my dear mycroft the brothers life is more than these folk here in spite of the door mr \n",
      "5.  my dear young lady we have so much for the man was crouching at the window the card \n",
      "6.  my dear inspector you have formed any explanation of his had the hint from holmes that you can \n",
      "7.  my dear sir it is inconceivable that it was finally agreed however that he was afraid of no \n",
      "8.  my dear fellow we imagine that she acted in this if you told them that he must act \n",
      "9.  my dear watson you have never gone out precisely yes i met theresa wright is her ring it \n",
      "10.  my dear fellow what do the criminal part its not been fed for two days after this brunton \n",
      "11.  my dear watson you wont fail me you know mr gilchrist how you an opinion upon what point \n",
      "12.  my dear fellow in the matter remained in the same paper had fallen away in parts in this \n",
      "13.  my dear watson he added as our client you will excuse these remarks from one who is in \n",
      "14.  my dear gregory you anticipate all my wants are simple and ames the faithful little creature an airedale \n",
      "15.  my dear fellow i often think of those minute and laborious investigations which formed the solid basis on \n",
      "16.  my dear watson was asking for your criticism it is an awful smell of the moist earth to \n",
      "17.  my dear watson said he listen to this man mortimer tregennis having been the last man that i \n",
      "18.  my dear fellow you will find it to be supernatural the other with stout cord the door itself \n",
      "19.  my dear watson that i shall be back by three men appeared on the ground floor in the \n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_story(markov_model, start=\"my dear\", limit=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.  i would have thought it and that is what mr lestrade of scotland yard officials messrs lestrade and \n",
      "1.  i would not leave a tongue with power to wag in a despairing voice a fortnight went by \n",
      "2.  i would prove it anyhow but what do you think of miss minnie warrender tut you will find \n",
      "3.  i would ask you to have a word or moving a muscle from morning to night on these \n",
      "4.  i would spend my life hiking round the old village inn he talked slowly and at least throw \n",
      "5.  i would not have been driven to ask you one or two more points to bring the facts \n",
      "6.  i would not have me leave it a ball of stout twine i think he is an elderly \n",
      "7.  i would not i it is a very pretty hash you have excluded the impossible whatever remains however \n",
      "8.  i would always carry the case pray let me hear the end mr mac it is less than \n",
      "9.  i would rather not do so and asked me rather an irregular pioneer who goes in front of \n",
      "10.  i would not do it there comes a time when my father made the parting easier than it \n",
      "11.  i would bring the experiment to an end then as i tried it when weve had no such \n",
      "12.  i would have the credit of being the nearest to the entrance to his feet and the lantern \n",
      "13.  i would be after standing back a little bewildered said he i feel a bit out of the \n",
      "14.  i would father if i call him mine but really as a judicious man as a to his \n",
      "15.  i would take it you will find it was neville st clairs coat and bowler hat not at \n",
      "16.  i would rather die under my orders you know very well that makes it a few words in \n",
      "17.  i would do justice upon him i suppose that it was the victim of some absurd illusion holmes \n",
      "18.  i would not venture to say that we are going to see sherlock holmes you compel me to \n",
      "19.  i would see her face in her pinafore and sobbing while i am staying there while i get \n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print(str(i)+\". \", generate_story(markov_model, start=\"i would\", limit=8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the case in his rooms of a certain window but the weather wait a bit though theres the varnish too like earth on each side of his brow was all changed when he understood the relations between us i am an omnivorous reader with a strangely retentive memory for trifles he answered laughing besides we may be comfortable in the fifth year and has got a glimpse of by the heels in the italian colony he had once contained the pure soul of lucy ferrier the wanderer explained me and made my dark room up there presently i think colonel that you had intended before his departure by the way she came to mr garcia wisteria lodge it was nearly midway between the oak that must have been examined in every way signor castalotte was a double stream upon the of the few clear days which our start had given jefferson hope lingered among the mountains for two as soon as you what happened then she died just a week in london or has impressed those who were as elated as if he were in baker street that will do said he in answer to my real occupation my dear watson but \n"
     ]
    }
   ],
   "source": [
    "print(generate_story(markov_model, start=\"the case\", limit=100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
